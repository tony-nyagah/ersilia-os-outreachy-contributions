{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Scikit-learn array API support was enabled but scipy's own support is not enabled. Please set the SCIPY_ARRAY_API=1 environment variable before importing sklearn or scipy. More details at: https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, balanced_accuracy_score\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/__init__.py:52\u001b[39m\n\u001b[32m     48\u001b[39m     sys.stderr.write(\u001b[33m\"\u001b[39m\u001b[33mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m         combine,\n\u001b[32m     54\u001b[39m         ensemble,\n\u001b[32m     55\u001b[39m         exceptions,\n\u001b[32m     56\u001b[39m         metrics,\n\u001b[32m     57\u001b[39m         over_sampling,\n\u001b[32m     58\u001b[39m         pipeline,\n\u001b[32m     59\u001b[39m         tensorflow,\n\u001b[32m     60\u001b[39m         under_sampling,\n\u001b[32m     61\u001b[39m         utils,\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/combine/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mSMOTEENN\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSMOTETomek\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/combine/_smote_enn.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/base.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/utils/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     check_neighbors_object,\n\u001b[32m      8\u001b[39m     check_sampling_strategy,\n\u001b[32m      9\u001b[39m     check_target_type,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m __all__ = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_neighbors_object\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_sampling_strategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_target_type\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSubstitution\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/utils/_validation.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[32m     22\u001b[39m SAMPLING_KIND = (\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mover-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munder-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbypass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m TARGET_KIND = (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultilabel-indicator\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/imblearn/utils/_sklearn_compat.py:815\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m(**_dataclass_args())\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTags\u001b[39;00m(Tags):\n\u001b[32m    813\u001b[39m     sampler_tags: SamplerTags | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_test_common\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstance_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    816\u001b[39m     _construct_instances,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    817\u001b[39m )\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_checks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    819\u001b[39m     check_estimator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    820\u001b[39m     parametrize_with_checks,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    821\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:179\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m all_estimators\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tags\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SkipTest\n\u001b[32m    181\u001b[39m CROSS_DECOMPOSITION = [\u001b[33m\"\u001b[39m\u001b[33mPLSCanonical\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPLSRegression\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCCA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPLSSVD\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# The following dictionary is to indicate constructor arguments suitable for the test\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# suite, which uses very small datasets, and is intended to run rather quickly.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/sklearn/utils/_testing.py:318\u001b[39m\n\u001b[32m    314\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     \u001b[43m_check_array_api_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     ARRAY_API_COMPAT_FUNCTIONAL = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ersilia/lib/python3.12/site-packages/sklearn/utils/_array_api.py:123\u001b[39m, in \u001b[36m_check_array_api_dispatch\u001b[39m\u001b[34m(array_api_dispatch)\u001b[39m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    117\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSciPy must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_scipy_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or newer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m (found \u001b[39m\u001b[38;5;132;01m{scipy.__version__}\u001b[39;00m\u001b[33m) to dispatch array using\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m the array API specification\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m     )\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mSCIPY_ARRAY_API\u001b[39m\u001b[33m\"\u001b[39m) != \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mScikit-learn array API support was enabled but scipy\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms own support is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot enabled. Please set the SCIPY_ARRAY_API=1 environment variable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbefore importing sklearn or scipy. More details at: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Scikit-learn array API support was enabled but scipy's own support is not enabled. Please set the SCIPY_ARRAY_API=1 environment variable before importing sklearn or scipy. More details at: https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Create the dataset from the image data\n",
    "def create_dataset():\n",
    "    \"\"\"Create a dataset from the compounds in the image\"\"\"\n",
    "    data = {\n",
    "        'Drug_ID': ['Drug 1', 'Drug 2', 'Drug 3', 'Drug 4', 'Drug 6'],\n",
    "        'Drug': [\n",
    "            'O=[N+]([O-])c1c2c(c3ccc4cccc5ccc3c45)CCCC2',\n",
    "            'O=c1c2ccccc2c(=O)c2c1ccc1c2[nH]c2c3c(=O)c4cccc...',  # Note: truncated in image\n",
    "            '[N-]=[N+]=CC(=O)NCC(=O)NN',\n",
    "            '[N-]=[N+]=C1C=NC(=O)NC1=O',\n",
    "            'CCCCN(CC(O)C1=CC(=[N+]=[N-])C(=O)C=C1)N=O'\n",
    "        ],\n",
    "        'Y': [1, 0, 1, 1, 1]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 2. Set up Ersilia and fetch models\n",
    "def setup_ersilia(model_id):\n",
    "    \"\"\"Set up Ersilia and fetch the specified model\"\"\"\n",
    "    # Initialize Ersilia\n",
    "    subprocess.run([\"ersilia\", \"init\"], check=True)\n",
    "    \n",
    "    # Fetch the model\n",
    "    subprocess.run([\"ersilia\", \"fetch\", model_id], check=True)\n",
    "    \n",
    "    # Serve the model\n",
    "    subprocess.run([\"ersilia\", \"serve\", model_id], check=True)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# 3. Generate features using Ersilia models\n",
    "def generate_features(smiles_list, port=3000):\n",
    "    \"\"\"Generate molecular features using Ersilia API\"\"\"\n",
    "    features_list = []\n",
    "    for smile in smiles_list:\n",
    "        response = requests.post(\n",
    "            f\"http://localhost:{port}/predict\",\n",
    "            json={\"input\": [smile]}\n",
    "        )\n",
    "        features = response.json()[\"output\"][0]\n",
    "        features_list.append(features)\n",
    "    \n",
    "    return np.array(features_list)\n",
    "\n",
    "# 4. Apply SMOTE to handle class imbalance\n",
    "def apply_smote(X, y):\n",
    "    \"\"\"Apply SMOTE to handle class imbalance\"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# 5. Evaluate model using leave-one-out cross-validation\n",
    "def evaluate_model(X, y):\n",
    "    \"\"\"Evaluate model using leave-one-out cross-validation\"\"\"\n",
    "    # For extremely small datasets, use leave-one-out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "    \n",
    "    # Use balanced accuracy since classes are imbalanced\n",
    "    scores = cross_val_score(clf, X, y, cv=loo, scoring='balanced_accuracy')\n",
    "    \n",
    "    print(f\"Leave-one-out cross-validation scores: {scores}\")\n",
    "    print(f\"Mean balanced accuracy: {scores.mean():.4f}\")\n",
    "    \n",
    "    # Also fit a model on all data (for external validation)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf, scores.mean()\n",
    "\n",
    "# 6. Extract important chemical features\n",
    "def extract_important_features(model, ersilia_model_id):\n",
    "    \"\"\"Extract important features based on the model\"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        print(\"Top 10 most important features:\")\n",
    "        for i in range(min(10, len(importances))):\n",
    "            print(f\"Feature {indices[i]}: {importances[indices[i]]:.4f}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 7. Main function\n",
    "def main():\n",
    "    # Create dataset\n",
    "    print(\"Creating dataset from image data...\")\n",
    "    data = create_dataset()\n",
    "    print(f\"Dataset shape: {data.shape}\")\n",
    "    \n",
    "    # Extract SMILES and targets\n",
    "    smiles_list = data['Drug'].tolist()\n",
    "    y = data['Y'].values\n",
    "    \n",
    "    # Models to try\n",
    "    model_options = [\n",
    "        \"eos2ta5\",  # Morgan fingerprints (simpler, better for small datasets)\n",
    "        \"eos2r5r\",  # Molecular descriptors (interpretable features)\n",
    "        \"eos4rbt\"   # Chemical language model embeddings (may overfit with small data)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for model_id in model_options:\n",
    "        print(f\"\\nSetting up Ersilia model: {model_id}\")\n",
    "        setup_ersilia(model_id)\n",
    "        \n",
    "        print(\"Generating features...\")\n",
    "        X = generate_features(smiles_list)\n",
    "        \n",
    "        # Check dimensions\n",
    "        print(f\"Feature matrix shape: {X.shape}\")\n",
    "        \n",
    "        # Skip SMOTE if dimensions are incompatible\n",
    "        if X.shape[1] >= 2:  # SMOTE requires at least 2 features\n",
    "            print(\"Applying SMOTE to handle class imbalance...\")\n",
    "            X_resampled, y_resampled = apply_smote(X, y)\n",
    "            print(f\"Resampled data shape: {X_resampled.shape}\")\n",
    "        else:\n",
    "            print(\"Warning: Cannot apply SMOTE with the current feature set\")\n",
    "            X_resampled, y_resampled = X, y\n",
    "        \n",
    "        print(\"Evaluating model...\")\n",
    "        clf, mean_score = evaluate_model(X_resampled, y_resampled)\n",
    "        \n",
    "        # Extract important features\n",
    "        if model_id in [\"eos2r5r\", \"eos2ta5\"]:  # Only for interpretable features\n",
    "            extract_important_features(clf, model_id)\n",
    "        \n",
    "        # Store results\n",
    "        results[model_id] = {\n",
    "            \"mean_score\": mean_score,\n",
    "            \"model\": clf\n",
    "        }\n",
    "        \n",
    "        # Close the model\n",
    "        subprocess.run([\"ersilia\", \"close\"], check=True)\n",
    "    \n",
    "    # Find best model\n",
    "    if results:\n",
    "        best_model_id = max(results, key=lambda k: results[k][\"mean_score\"])\n",
    "        print(f\"\\nBest model: {best_model_id} with mean balanced accuracy {results[best_model_id]['mean_score']:.4f}\")\n",
    "    \n",
    "    # Warning about small dataset\n",
    "    print(\"\\nWARNING: This model is based on a very small dataset (5 compounds)\")\n",
    "    print(\"Results should be interpreted with caution and additional validation is strongly recommended\")\n",
    "    print(\"Consider adding more compounds to the dataset for better predictive performance\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ersilia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
